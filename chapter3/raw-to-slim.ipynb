{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import autograd\n",
    "import autograd.numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import autocrit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "\n",
    "import shared.format\n",
    "import shared.tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.size\"] = shared.format.FONTSIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", category=FutureWarning,\n",
    "    message=\"Using a non-tuple sequence for multidimensional indexing is deprecated;\",\n",
    "    module=\"autograd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autocrit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autocrit_tools\n",
    "import autocrit_tools.linearpaper.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_dir = pathlib.Path(\"data\") / \"linear-results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_index(spectrum, eigval_cutoff=1e-5):\n",
    "    return np.mean(spectrum < -eigval_cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs = [1e-10, 1e-6, 1e-4, np.inf]\n",
    "cutoff_strings = [r\"$\\varepsilon=$1e-10\", r\"$\\varepsilon=$1e-6\", r\"$\\varepsilon=$1e-4\", \"no cutoff\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_fnames = [\"1e-10\", \"1e-6\", \"1e-4\", \"none\"]\n",
    "\n",
    "cutoff_cp_df_names= [pickle_dir / (\"cutoff_\" + cutoff_fname + \".pkl\")\n",
    "                     for cutoff_fname in cutoff_fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autocrit_tools.path as path\n",
    "import autocrit_tools.dataframes as dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_path_columns(df, path_columns, split_str, new_prefix):\n",
    "    for path_column in path_columns:\n",
    "        df[path_column] = df[path_column].apply(clean_path, args=(split_str, new_prefix))\n",
    "        \n",
    "def clean_path(path, split_str, new_prefix):\n",
    "    path_end = path.split(split_str)[-1]\n",
    "    return os.path.join(new_prefix, path_end)\n",
    "\n",
    "def add_index_sets(cp_df):\n",
    "    maps = cp_df.final_theta.apply(\n",
    "        lambda theta: utils.theta_to_map(theta, NETWORK))\n",
    "    index_sets = [utils.map_to_index_set(_map) for _map in maps]\n",
    "\n",
    "    cp_df[\"index_set\"] = index_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ID = \"linear-results\"\n",
    "network_ID = \"dlae\"\n",
    "\n",
    "network_paths = path.ExperimentPaths(data_ID=data_ID, network_ID=network_ID, root=root_dir)\n",
    "\n",
    "target_optimization_ID = \"gd_optimizer_fimeXE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_df = dataframes.construct_experiments_df(\n",
    "    network_paths.network_dir)\n",
    "\n",
    "target_optimization_row = optimization_df.loc[target_optimization_ID]\n",
    "\n",
    "data, NETWORK, _ = dataframes.reconstruct_from_row(\n",
    "    target_optimization_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_paths = path.ExperimentPaths.from_optimizer_dir(target_optimization_row.optimizer_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "critfinders_dir = optimizer_paths.optimizer_dir\n",
    "\n",
    "cf_df = dataframes.construct_experiments_df(\n",
    "    critfinders_dir, experiment_type=\"critfinder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_cf_df = pd.DataFrame.from_dict(\n",
    "    dict(cf_df.finder_kwargs_finder)\n",
    "    ).transpose().join(cf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_critfinders(cf_df, method_str, theta_perturbs=None, init_theta=\"uniform_f\", \n",
    "                       min_runs=0, max_runs=1000):\n",
    "    \n",
    "    selector = cf_df.index.str.startswith(method_str) &\\\n",
    "               cf_df.init_theta_experiment.str.endswith(init_theta)\n",
    "    \n",
    "    if theta_perturbs is None:\n",
    "        selector = selector & cf_df.theta_perturb_experiment.isnull()\n",
    "    else:\n",
    "        selector = selector & cf_df.theta_perturb_experiment.isin(theta_perturbs)\n",
    "    \n",
    "    cf_ids = expanded_cf_df.index[selector]\n",
    "    \n",
    "    cp_dfs =  utils.make_cp_dfs(cf_ids, cf_df)\n",
    "    \n",
    "    try:\n",
    "        cp_dfs, cf_ids = zip(*[(cp_df, cf_id) for cp_df, cf_id in zip(cp_dfs, cf_ids)\n",
    "                               if (len(cp_df) >= min_runs) & (len(cp_df) <= max_runs)])\n",
    "    except ValueError:\n",
    "        cp_dfs = cf_ids = []\n",
    "    \n",
    "    \n",
    "    return cp_dfs, list(cf_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_candidate_cp(cp_df, network, return_failures=False, cp_cutoff=1e-10):\n",
    "    \n",
    "    if return_failures:\n",
    "        candidate_cp_df, failures_df = utils.filter_to_candidate_cps(\n",
    "            cp_df, network, cp_cutoff=cp_cutoff, return_failures=True)\n",
    "        candidate_cp_df[\"morse_index\"] = utils.get_hessian_info(\n",
    "            candidate_cp_df.candidate_theta, network)[-1]\n",
    "        return candidate_cp_df, failures_df\n",
    "    else:\n",
    "        candidate_cp_df = utils.filter_to_candidate_cps(\n",
    "            cp_df, network, cp_cutoff=cp_cutoff, return_failures=False)\n",
    "        candidate_cp_df[\"morse_index\"] = utils.get_hessian_info(\n",
    "            candidate_cp_df.candidate_theta, network)[-1]\n",
    "        \n",
    "        return candidate_cp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Comparison Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "MR_cp_dfs, MR_cf_ids = select_critfinders(expanded_cf_df,\n",
    "                                          method_str=\"newtonMR\",\n",
    "                                         theta_perturbs=[None, -2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "TR_cp_dfs, TR_cf_ids = select_critfinders(expanded_cf_df,\n",
    "                                          method_str=\"newtonTR\",\n",
    "                                         theta_perturbs=[None, -2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnm_cp_dfs, gnm_cf_ids = select_critfinders(expanded_cf_df,\n",
    "                                          method_str=\"gnm\",\n",
    "                                         theta_perturbs=[None, -2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_MR_cp_df = pd.concat(MR_cp_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_TR_cp_df = pd.concat(TR_cp_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_gnm_cp_df = pd.concat(gnm_cp_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_MR_candidate_cp_df, merged_MR_failures_df = to_candidate_cp(\n",
    "    merged_MR_cp_df, NETWORK,\n",
    "    return_failures=True, cp_cutoff=1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_TR_candidate_cp_df, merged_TR_failures_df = to_candidate_cp(\n",
    "    merged_TR_cp_df, NETWORK,\n",
    "    return_failures=True, cp_cutoff=1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_gnm_candidate_cp_df, merged_gnm_failures_df = to_candidate_cp(\n",
    "    merged_gnm_cp_df, NETWORK,\n",
    "    return_failures=True, cp_cutoff=1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_slim(cp_df):\n",
    "    slim_df = cp_df.copy()\n",
    "    columns_to_drop = [\n",
    "        \"log_kwargs\", \"alpha\", \"beta\", \"rho\", \"check_pure\", \"rho_pure\",\n",
    "        \"log_mrqlp\", \"rtol\", \"maxit\", \"thetas\", \"run_length\", \"alphas\",\n",
    "        \"step_size\", \"gammas\", \"pure_accepted\"]\n",
    "    for column in columns_to_drop:\n",
    "        try:\n",
    "            slim_df = slim_df.drop(axis=\"columns\", labels=[column])\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return slim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "slim_TR_candidate_df = make_slim(merged_TR_candidate_cp_df)\n",
    "slim_TR_failures_df = make_slim(merged_TR_failures_df)\n",
    "\n",
    "slim_TR_candidate_df.to_pickle(\"data/linear-results/newtonTR-success.pkl\")\n",
    "slim_TR_failures_df.to_pickle(\"data/linear-results/newtonTR-failure.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "slim_MR_candidate_df = make_slim(merged_MR_candidate_cp_df)\n",
    "slim_MR_failures_df = make_slim(merged_MR_failures_df)\n",
    "\n",
    "slim_MR_candidate_df.to_pickle(\"data/linear-results/newtonMR-success.pkl\")\n",
    "slim_MR_failures_df.to_pickle(\"data/linear-results/newtonMR-failure.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "slim_gnm_candidate_df = make_slim(merged_gnm_candidate_cp_df)\n",
    "slim_gnm_failures_df = make_slim(merged_gnm_failures_df)\n",
    "\n",
    "slim_gnm_candidate_df.to_pickle(\"data/linear-results/gnm-success.pkl\")\n",
    "slim_gnm_failures_df.to_pickle(\"data/linear-results/gnm-failure.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cutoffs Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cutoff_cp_df(cp_df, network, cp_cutoff):\n",
    "    cutoff_cp_df, failures_df = utils.filter_to_candidate_cps(\n",
    "        cp_df, network, cp_cutoff=cp_cutoff, return_failures=True, cut_early=True)\n",
    "    cutoff_cp_df[\"morse_index\"] = utils.get_hessian_info(\n",
    "        cutoff_cp_df.candidate_theta, network)[-1]\n",
    "    return cutoff_cp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_cp_dfs = [make_cutoff_cp_df(merged_MR_cp_df, NETWORK, cutoff) for cutoff in cutoffs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slim_cutoff_cp_dfs = [make_slim(cutoff_cp_df) for cutoff_cp_df in cutoff_cp_dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[cutoff_cp_df.to_pickle(cutoff_cp_df_name)\n",
    " for cutoff_cp_df, cutoff_cp_df_name in zip(cutoff_cp_dfs,cutoff_cp_df_names)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autocrit_tools.linearpaper.panels as panels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panels.make_trajectory_panel(merged_MR_candidate_cp_df,\n",
    "                             merged_MR_failures_df);\n",
    "plt.xscale(\"linear\"); plt.xlim(0, 500);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panels.make_loss_index_panel(merged_MR_candidate_cp_df,\n",
    "                             analytical_cp_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonlinear-Failure Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonlinear_failure_candidate_cp_df = pd.read_pickle(\n",
    "    \"data/nonlinear-results/dnn-failure-full-success.pkl\")\n",
    "nonlinear_failure_failures_df = pd.read_pickle(\n",
    "    \"data/nonlinear-results/dnn-failure-full-failure.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "slim_nonlinear_failure_candidate_df = make_slim(nonlinear_failure_candidate_cp_df)\n",
    "slim_nonlinear_failure_failures_df = make_slim(nonlinear_failure_failures_df)\n",
    "\n",
    "slim_nonlinear_failure_candidate_df.to_pickle(\"data/nonlinear-results/dnn-failure-success.pkl\")\n",
    "slim_nonlinear_failure_failures_df.to_pickle(\"data/nonlinear-results/dnn-failure-failure.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
